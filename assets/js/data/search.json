[ { "title": "Introducing Audio in QR Codes", "url": "/posts/introducing-ARQ/", "categories": "tech", "tags": "audio, qr code", "date": "2025-02-22 15:00:00 -0800", "snippet": "github link: https://github.com/planewave/audio-in-QR/A prototype implementation that embeds and plays short audio clips through QR codes.一个将短音频嵌入 QR 码并播放的原型实现。Overview / 概述This is a unique project that stores and plays short audio clips via QR codes. Despite being an interesting concept, there aren’t many similar implementations available.这是一个独特的项目，通过 QR 码存储和播放短音频。尽管这是个有趣的想法，但目前还没有发现类似的实现。Currently, a QR code can store approximately 1.2 seconds of clear audio using this method.目前使用该方法，一个 QR 码可以存储约 1.2 秒的清晰音频。Features / 特点 Offline playback - all audio data is stored in the QR code 离线播放 - 所有音频数据都存储在 QR 码中 iOS Shortcut support (Download) 支持 iOS 快捷指令（下载链接） Android support via Tasker (not provided) 支持通过 Tasker 在 Android 上使用 （未提供）How to Use / 使用方法 Prepare an audio clip (~1 second) 准备一段音频（约 1 秒） Compress using FFmpeg with Opus codec: 使用 FFmpeg 和 Opus 编码压缩： ffmpeg -i input.wav -c:a libopus -b:a 8k -ac 1 -ar 8000 output.mp4 Convert to QR code using qr_gen.py, (requires qrcode library) 使用qr_gen.py转换为 QR 码, (需要安装 qrcode 库) Scan and play using iOS Shortcut or Android Tasker 使用 iOS 快捷指令或 Android Tasker 扫描并播放Technical Details / 技术细节 Uses QR code version 40 (max ~3KB data capacity) 使用 QR 码版本40（最大约 3KB 数据容量） Base64 encoding for compatibility 使用 Base64 编码以确保兼容性 Opus audio codec in MP4 container for iOS 17+ compatibility 使用 MP4 容器的 Opus 音频编码以兼容 iOS 17+Future Improvements / 未来改进 Custom app could use binary QR codes to save 33% space 专用应用可以使用二进制 QR 码来节省33%空间 Potential for 2-second audio with binary QR codes and optimized compression 通过二进制 QR 码和优化压缩，有潜力实现2秒音频Credits / 致谢Sample audio from freesound.org示例音频来自 freesound.org" }, { "title": "除夕夜的回忆", "url": "/posts/Chinese-new-year/", "categories": "logs", "tags": "", "date": "2025-01-28 15:00:00 -0800", "snippet": "回忆小时候过年，印象最深刻的是在东北农村爷爷奶奶家过年。我们三家人, 加上二叔和老叔两家一起在爷爷奶奶家过年。孩子们一起玩，那段时间是难得的和弟弟妹妹们一起玩的机会。大家都穿着漂亮的衣服，吃着好吃的零食，但具体玩什么已经记不清了。吃年夜饭时，家里有个大圆桌，上面摆满了各种鱼肉菜，中间是个烧木炭的铜火锅，大家都吃涮羊肉。爷爷总怕肉不熟，不让我们早早把肉捞出来。大人们喝啤酒，没有精美的酒杯，我记得甚至用的是一次性的塑料杯。饭后看春晚，用的是那种很小的显像管电视，右侧有很多按键和旋钮。我最喜欢看小品和相声，尤其是赵本山的节目，而对歌舞类节目完全不感兴趣。另一些大人在另一个屋子包饺子，但真正吃饺子的时候，我已经吃饱了，只能象征性地吃几个。12点时，大家一起倒计时，然后喊“新年快乐”。孩子们找爷爷奶奶拜年，收红包，每人大概100元。这里我有点记不清了，也可能是大年初一早上去拜年。还有放鞭炮。我过去挺喜欢放鞭炮的，但爷爷奶奶非常担心，因为他看过太多放鞭炮受伤的事，所以不让我们放特别大型的鞭炮，只能放吐球和呲花，在家里的小气窗口放。而窜天猴和二踢脚只能远远看其他孩子玩。长大后，我对放鞭炮的兴趣很快就消失了，现在甚至觉得放鞭炮很吵闹。红灯笼，家家户户在阳台上都有红灯笼，住平房的在家门口挂红灯笼。最早是中间放蜡烛的，后来改成白炽灯。灯笼的骨架最早是竹丝，后来是铁丝，但外面的红布永远不变。我特别喜欢看灯笼，除夕夜会独自跑去阳台看灯笼，但因为很冷，很快就回屋里了。等春晚结束，快一点了，我们就该睡觉了。我不知道从哪里听说的“守岁”这个说法，挣扎着要熬夜到第二天，但当然挺不了多久就睡了。另一边，大人们一起打麻将会到很晚。我被教育打麻将是不好的游戏，所以到现在我也不会玩麻将。现在我在路边行走时，偶尔会恍惚觉得自己走在东北农村冬天的野地里。白雪覆盖的大地，密密长着枯黄的高草。隆起的石头在一层白雪下面露出黑色的纹理。冻结的水塘上，露出的灰白冰面透着一丝蓝色。呼吸冰冷的空气让我感到非常熟悉。冷风吹过时，自然地将围巾拉起。中年的我似乎又回到了过去的记忆中。" }, { "title": "Understanding RF Impairments - Part 5", "url": "/posts/rf-impairment-5/", "categories": "RF", "tags": "interview, Impairment, transceiver", "date": "2025-01-10 12:00:00 -0800", "snippet": "Understanding IQ ImbalanceIntroductionIn the previous article, we discussed the architecture of zero-IF transceivers and the DC offset impairment. This article will dive into another significant impairment closely related to the zero-IF transceiver architecture: IQ imbalance.IQ ImbalanceWhen working with the USRP, I frequently encountered an issue: an image signal at the opposite frequency of the original signal, degrading the overall capture quality.For instance, if a sine wave is received at the frequency $f_c$, there is always an unwanted sine wave at $-f_c$. Although generally weaker in power compared to the main signal, it is still a major distortion for many zero-IF transceivers. This phenomenon is caused by IQ imbalance.Image signal due to IQ imbalance (from Matlab documentation)This issue may not seem intuitive. How does IQ imbalance generate an image signal? And more importantly, what exactly is IQ imbalance?Causes of IQ ImbalanceLet’s review the architecture of a zero-IF receiver, as shown below:Block diagram of a zero-IF receiver (from wirelesspi.com)In the last article, we mentioned the following: The mixers downconvert the RF signal to baseband by multiplying it with quadrature sine waves. The two sine waves are generated by the LO, ensuring identical amplitude and a 90-degree phase difference. The mixers’ output comprises the in-phase (I) and quadrature (Q) components of the baseband signal. The LPFs filter out high-frequency components, leaving only the desired baseband signal.However, analog components cannot perfectly generate two sine waves with identical amplitude and phase, leading to IQ imbalance impairment.For example, a 16-QAM signal affected by IQ imbalance can be visualized as follows:Distorted constellation due to IQ imbalance (image from Matlab documentation)Here, the red crosses represent the ideal constellation points, while the yellow dots represent the distorted points caused by IQ imbalance.So far, the distortion in the constellation is relatively intuitive, but why is there an image signal? One way to understand it is by visualizing the sine wave as a rotating vector in the complex (IQ) plane. Without IQ imbalance, the trace forms a perfect circle. However, with IQ imbalance, the trace becomes an oval, which can be decomposed into two rotating circles with the same freuqency but opposite directions and different radii. The circle with the smaller radius represents the image signal. While the exact proof is omitted here, this provides an intuitive understanding of the image signal.Mathematical ModelLet’s model the IQ imbalance impairment mathematically. The LO’s output in the I and Q branches can be expressed as $cos(w_c t)$ and $-sin(w_c t)$, respectively. By applying a phase difference $\\phi$ and a gain difference $g$ to the Q branch, the overall LO output becomes:\\[a(t) = \\cos(\\omega_c t) - jg \\sin(\\omega_c t + \\phi)\\]where $j$ is the imaginary unit.Using Euler’s formula, this equation can be rewritten as:\\[a(t) = \\left( \\frac{1 + g e^{-j \\phi}}{2} \\right) e^{-j \\omega_c t} + \\left( \\frac{1 - g e^{j \\phi}}{2} \\right) e^{j \\omega_c t}\\]Then we collect the coefficients of $e^{-j \\omega_c t}$ and $e^{j \\omega_c t}$, we have\\[a(t) = \\left( \\frac{1 + g e^{-j \\phi}}{2} \\right) e^{-j \\omega_c t} + \\left( \\frac{1 - g e^{j \\phi}}{2} \\right) e^{j \\omega_c t}\\]defing $K_1 = \\frac{1 + g e^{-j \\phi}}{2}$ and $K_2 = \\frac{1 - g e^{j \\phi}}{2}$, we have:\\[a(t) = K_1 e^{-j \\omega_c t} + K_2 e^{j \\omega_c t}\\]The image signal is brought by the second term $K_2 e^{j \\omega_c t}$.Without IQ imbalance (i.e., $g=1$ and $\\phi=0$), we have $K_1 = 1$ and $K_2 = 0$, indicating no image signal.Image Rejection RatioThe image rejection ratio (IRR) quantifies the level of IQ imbalance. It indicates the dB difference between the desired and unwanted signals, reflecting how effectively the unwanted signal is suppressed.\\[\\text{IRR} = 10 \\cdot \\log_{10} \\left( \\frac{P_{\\text{desired}}}{P_{\\text{image}}} \\right) = 10 \\log_{10} \\frac{|K_1|^2}{|K_2|^2}\\]Image rejection ratioImpact of IQ imbalanceIn a single-carrier system, the magnitude and phase of the constellation points change linearly due to IQ imbalance. In addition, the IQ imbalance is particularly problematic for OFDM systems. It generates ICI terms on symmetry subcarriers, degrading system performance.Compensation TechniquesIf the signal bandwidth is within a few percent of the carrier frequency, it can generally be treated as frequency-independent. However, for larger signal bandwidths, the frequency dependence of the image interference may need consideration.Some transceivers have built-in IQ imbalance compensation algorithms. For instance, the USRP includes a calibration routine to compensate for IQ imbalance.MATLAB also offers a function, comm.IQImbalanceCompensator, for this purpose. The compensated signal is expressed as $y(n) = x(n) + wx^*(n)$.Block diagram of IQ imbalance compensator (from Matlab documentation)ConclusionIQ imbalance is a significant impairment in zero-IF transceivers, resulting in distorted constellations and image signals that degrade system performance. Understanding its causes, modeling it mathematically, and employing effective compensation techniques are essential for mitigating its impact, particularly in advanced communication systems.This article marks the end of my series on RF impairments. I hope you have gained some understanding of these impairments and their impact on communication systems. I found them essential when applying for an RF system integration position, and I hope they will be useful for you as well.If you have any questions or suggestions, feel free to reach out to me. Thank you for reading!" }, { "title": "Happy New Year!", "url": "/posts/new-year/", "categories": "logs", "tags": "", "date": "2024-12-31 16:00:10 -0800", "snippet": "2025 新年快乐1月1号和12月31号没有什么本质不同, 仅仅是日历翻动了平常的一页.但是心理上, 却完全不一样.因为人总是喜欢有一个节点, 一个时间点, 一个事件, 来标志着新的开始.1月1号, 作为这样一个节点再适合不过了.我知道, 我的生活需要改变, 我的认知需要提升.总结了去年的波澜, 认识了自己, 人生无常, 也见识了世人的阴暗面.要学会接受和放弃, 学会取舍, 学会坚强.发现自己要学习的东西还有太多太多. 在这里做个计划, 说不定能坚持下去.学习上的计划: C++, 算法与数据结构 批判性思维 博弈论生活上的计划: 找到工作之外的生活支柱 保持健康的生活方式 对家人关爱尽责希望自己能够坚持下去. 让 2025 成为美好新生活的开始." }, { "title": "Understanding RF Impairments - Part 4", "url": "/posts/rf-impairment-4/", "categories": "RF", "tags": "interview, Impairment, transceiver, zero-IF, DC", "date": "2024-12-24 04:34:00 -0800", "snippet": "Understanding Zero-IF Transceivers and DC OffsetIntroductionZero-IF transceivers, also known as direct conversion transceivers, are widely used due to their simplicity and low cost. These attributes make them particularly suitable for applications where minimizing hardware complexity and expense is crucial, such as in consumer electronics and portable communication devices. However, they introduce several impairments, including DC offset and IQ imbalance. This article reviews their architecture and focuses on the DC offset impairment. The IQ imbalance will be addressed in a subsequent article.Direct Conversion ReceiversZero-IF transceivers are also referred to as direct conversion transceivers because they directly convert the RF signal to baseband without using an intermediate frequency (IF) stage.To understand the causes of DC offset and IQ imbalance, it is essential to examine the architecture, as it provides critical insights into how these impairments originate and propagate through the signal processing chain.The block diagram of a zero-IF receiver (the transmitter has a similar but reversed diagram) is shown below:block diagram of a zero-IF receiver from wirelesspi.comThe analog potion of the zero-IF receiver consists of a preselection filter, low noise amplifier (LNA), mixers, and lowpass filters (LPFs).Preselection FilterThe preselection filter might appear unnecessary at first glance, but it is essential to filter out unwanted signals, prevent out-of-band interference, and improve the receiver’s performance.Without the preselection filter (such as in some USRPs), the receiver may become saturated by strong out-of-band signals. Combined with the odd-order harmonics from the local oscillator (LO), the receiver may inadvertently pick up undesired signals.Low Noise Amplifier (LNA)The LNA amplifies the power of the received RF signal. Note the following points: The LNA does not increase the signal-to-noise ratio (SNR) of the received signal; it amplifies both the signal and noise, slightly degrading the SNR. Despite this, the LNA is necessary because the received signal may be too weak and could be overwhelmed by noise introduced in subsequent stages. The LNA ensures that the signal of interest maintains sufficient power for processing by the ADC, such that it is neither too weak to detect nor too strong to saturate the ADC. This mechanism is called automatic gain control (AGC). As the first stage, the LNA’s noise figure is crucial to the receiver’s overall noise performance. This is why a low-noise amplifier is required. Check out the previous article for more details. The counterpart of the LNA in the transmitter is the power amplifier (PA), which amplifies the signal power before transmission. The PA’s nonlinearity was discussed in this article.Mixers and LPFsThe mixers downconvert the RF signal to baseband by multiplying the RF signal with quadrature sinusoids.The two sinusoids are generated by the LO, ensuring they are identical in amplitude and have a 90-degree phase difference.The mixers’ output comprises the in-phase (I) and quadrature (Q) components of the baseband signal. The LPFs filter out high-frequency components, leaving only the desired baseband signal.DC OffsetThe spectrum of the IQ output of the ADC often includes a strong DC component, known as the DC offset.This impairment is caused by LO leakage in the mixers. LO leakage occurs when a portion of the LO signal inadvertently leaks into the RF input path, leading to interference. This leakage creates a zero-frequency component in the IQ output, manifesting as DC offset.DC offset is particularly problematic for single-carrier systems, such as QPSK, because it can shift constellation points, leading to errors in the demodulation process. For OFDM systems, the DC offset can often be mitigated by nulling out the DC carrier in the transmitted waveform. For instance, Wi-Fi systems null the DC carrier in OFDM waveforms.Many transceivers include DC offset cancellation circuits to mitigate this impairment. These circuits estimate the DC offset and subtract it from the IQ output or apply a filter to suppress the DC component. However, DC offset cancellation is not perfect and may introduce additional noise or impairments.ConclusionIn this article, we explored the architecture of zero-IF transceivers and the DC offset impairment. In the next article, we will examine the IQ imbalance impairment and its impact on wireless communication systems." }, { "title": "Understanding RF Impairments - Part 3", "url": "/posts/rf-impairment-3/", "categories": "RF", "tags": "interview, Impairment, CFO, nonlinear", "date": "2024-12-18 12:18:00 -0800", "snippet": "Carrier Frequency Offset and Phase NoiseIntroductionIn the previous articles, we discussed thermal noise and amplifier nonlinear distortion in wireless communication systems. In this article, we will explore other two common RF impairments: carrier frequency offset (CFO) and phase noise (PN). Both impairments arise due to imperfections in oscillators and must be addressed in the design of wireless systems.Carrier Frequency OffsetCarrier frequency offset, or CFO, is one of the most commonly encountered RF impairments and requires consideration in the design of almost all wireless receivers. It manifests as a frequency shift of the carrier in the received signal.In a single carrier system, the CFO can be visualized as a rotating constellation on the receiver side.The constellation of a 16QAM system rotates due to the CFO (from Matlab Documentation)Causes of CFOCFO can arise from: Frequency differences between local oscillators: Discrepancies between the transmitter and receiver oscillators. Doppler shift: Relative motion between the transmitter and receiver.Mathematical modelMathematically, the received signal $y(t)$ can be expressed as\\(y(t)=x(t)e^{j2\\pi(f_c+\\Delta f)t}\\)where $x(t)$ is the transmitted signal, $f_c$ is the carrier frequency, and $\\Delta f$ is the CFO.Imapact of CFOOFDM systems are particularly vulnerable to CFO because it introduces inter-channel interference, disrupting the orthogonality of OFDM subcarriers, introducing intercarrier interference (ICI).For example, at the 2.4 GHz band, CFO can reach tens of kilohertz, and at the 5.8 GHz band, it can reach hundreds of kilohertz. Wireless receiver design must account for CFO through estimation and compensation techniques.Measurement and CompensationSeveral schemes can estimate and compensate for CFO, with one common method utilizing the training sequence in the received signal.Example: CFO Compensation in LTECFO in LTE signals can be divided into two components: Integer CFO: An integer multiple of the subcarrier spacing (15 kHz). Fractional CFO: A remainder less than 15 kHz.Fractional CFO Estimation: Leveraging the cyclic prefix (CP) structure of OFDM signals, we estimate the fractional CFO by measuring the phase difference between the CP and the symbol tail, then dividing it by the symbol duration.Integer CFO Estimation: Using the Primary Synchronization Signal (PSS), a frequency-domain cross-correlation with a reference PSS reveals the integer CFO by identifying the correlation peak.Phase NoiseCause of PNPhase noise results from oscillator imperfections. It manifests as rapid, short-term, random fluctuations in the carrier wave phase.Observable effects Frequency domain: Spreading of the carrier around the center frequency. Time domain: Misalignment of the carrier phase.The phase noise observed in the frequency and time domainFor a single carrier system, the phase noise causes the constellation points to spread.The constellation of a QPSK system spreads due to the phase noiseMathematical modelWithout phase noise, the RF signal $y(t)$ can be simply written as\\(y(t)=x(t)e^{\\mathrm{j} 2 \\pi f_c t}\\)by taking into account the LO phase noise $\\theta(t)$\\(y(t)=x(t)e^{\\mathrm{j}(2\\pi f_c t + \\theta(t))}=x(t)e^{\\mathrm{j}2 \\pi f_c t}e^{\\mathrm{j}\\theta(t)}\\)The phase noise $\\theta(t)$ is commonly described in the frequency domain by its power spectral density (PSD) in dBc/Hz, representing the noise power ratio at a frequency offset to the carrier power.Impact of PNSimilar to the CFO, phase noise is especially detrimental in OFDM systems as it destroys subcarrier orthogonality, resulting in ICI.Comparison between CFO and PNWhile both CFO and PN stem from oscillator imperfections, their effects differ: CFO: A fixed offset in the frequency domain. PN: Random phase fluctuations in the carrier.Combined, CFO and PN can significantly degrade wireless system performance, particularly in OFDM systems.ConclusionIn this article, we discussed two common RF impairments: carrier frequency offset and phase noise. Both impairments are mainly introduced by the imperfection of the oscillator and must be considered in the design of wireless systems. The CFO can be estimated and compensated using the training sequence in the received signal, while the phase noise can be mitigated by using a high-quality oscillator. The combined effect of CFO and phase noise can significantly degrade the performance of the wireless system, especially in the OFDM system." }, { "title": "Understanding RF Impairments - Part 2", "url": "/posts/rf-impairment-2/", "categories": "RF", "tags": "interview, Impairment, amplifier, nonlinear, IP3, P1dB", "date": "2024-12-17 04:13:00 -0800", "snippet": "Amplifier Distortion in Wireless Communication SystemsIn wireless communication systems, RF impairments refer to factors that affect signal transmission quality, such as noise, nonlinear distortion, or frequency interference. Other than the thermal noise, a more comprehensible RF impairment is amplifier distortion.Amplifiers are critical components in the wireless transmitters and receivers. Positioned close to the antenna, their primary role is to amplify input signals to higher power levels while maintaining linearity. However, achieving both high power and linearity often involves trade-offs.Common Types of Amplifier Distortion Amplitude Distortion: When input power increases, the output signal’s amplitude is clipped or compressed. Phase Distortion: Nonlinearities introduce phase shifts, altering the signal’s phase information (will not be discussed here). Intermodulation Distortion (IMD): When multiple signals of different frequencies are input to an amplifier, its nonlinear characteristics cause these signals to mix, producing new frequency components.Amplitude DistortionIn an amplifier’s linear operating region, output power is proportional to input power and can be expressed as: Output Power = Input Power + Gain (on a dB scale). However, as input power continues to increase, the output deviates from this linear relationship and approaches a saturation limit, leading to amplitude distortion.A key parameter here is the 1 dB compression point (P1dB), which defines the input power level at which the output power is 1 dB below the theoretical linear output. This marks the boundary between the linear and nonlinear operating regions.Amplitude compression and P1dB (from everythingrf.com)Why is P1dB important? In applications where the linearity is critical, signal power must remain below P1dB (typically 3-5 dB lower) to avoid significant distortion and maintain signal quality.Example: Amplifying a QAM signal beyond the linear region compresses the outermost constellation points, leading to distortion and degraded performance.Amplitude Distortion for a QAM Signal (from Matlab Documentation)Why Operate Amplifiers in the Nonlinear Region?While operating in the linear region ensures signal integrity, it limits output power, making it inadequate for high-power signal transmission. To extend range or meet higher power requirements, amplifiers often operate in the nonlinear region. This trade-off balances output power and signal distortion, particularly in long-distance wireless systems.Mitigating Amplitude DistortionTo address the signal quality issues caused by nonlinear distortion, Digital Predistortion (DPD) is a widely used technique.Principle of Digital Predistortion: Measure the amplifier’s nonlinear characteristics to create a distortion model. Design an inverse filter to preprocess the input signal, introducing distortion opposite to the amplifier’s characteristics. After amplification, the preprocessed “distortion” cancels out the amplifier’s nonlinear distortion, restoring signal linearity.In simple terms, the input signal undergoes “predistortion” before amplification, ultimately compensating for the nonlinear effects. However, DPD is effective only when the amplifier operates within its non-saturated region and cannot extend the amplifier’s linear range indefinitely.Intermodulation Distortion (IMD)Harmonics and intermodulation are common forms of amplifier distortion, often occurring in nonlinear operating conditions. While amplifiers are primary sources, other nonlinear components can also generate these distortions.HarmonicsHarmonics are frequency components at integer multiples of the fundamental signal frequency, e.g., $2f, 3f, 4f$, etc. Their amplitudes decrease with increasing order.IntermodulationWhen two closely spaced single-frequency signals are present, their harmonics and fundamentals interact, producing intermodulation products. If the fundamental frequencies are $f_1$ and $f_2$, possible intermodulation frequencies include: Second-Order Products: $f_1 + f_2$, $f_1 - f_2$. Third-Order Products: $2f_1 + f_2, 2f_1 - f_2, f_1 + 2f_2, -f_1 + 2f_2$.Special attention is given to $2f_1 - f_2$ and $2f_2 - f_1$ due to their: Higher amplitudes at lower orders. Proximity to the original signal frequencies, making them difficult to filter. Increase in power by 3 dB for every 1 dB increase in input power.Intermodulation and third-order products (from Rohde &amp;amp; Schwarz)Third-order intermodulation distortion (IMD) is particularly significant. Assuming the RF device does not saturate, the point at which third-order intermodulation power equals the fundamental output power is the third-order intercept point (IP3 or IIP3). Though this point is theoretical due to compression effects, it serves as a key linearity metric. Higher IP3 values indicate better linearity and lower IMD.the IP3 point (from Rohde &amp;amp; Schwarz)IP3 MeasurementI found an very useful YouTube video that explains Third Order Intercept and how to measure it.IP3 Measurements (from Rohde &amp;amp; Schwarz)ConclusionAmplifier distortion is a critical consideration in wireless communication systems. While operating in the nonlinear region enables higher power outputs, it introduces signal distortion that degrades transmission quality. Key nonlinear effects include amplitude distortion, phase distortion, and intermodulation distortion, with intermodulation being particularly impactful due to the generation of additional frequency components within the operational band.By employing techniques like DPD and evaluating linearity metrics such as P1dB and IP3, designers can optimize amplifier performance, achieving a balance between efficiency and linearity. Striking this balance is essential for delivering reliable and high-quality communication." }, { "title": "Understanding RF Impairments - Part 1", "url": "/posts/rf-impairment-1/", "categories": "RF", "tags": "interview, noise", "date": "2024-12-14 08:40:00 -0800", "snippet": "RF Impairments OverviewIn a wireless communication system, various factors can distort the received signal. When the distortion originates from the imperfections of analog components in the transceivers, it is referred to as RF impairment. Other causes include channel fading or synchronization issues. These impairments introduce interference and degrade the performance of wireless systems.The ability to mitigate RF impairment is often a key measure of the quality of a radio product.flowchart LR subgraph TX [&quot;Transmitter&quot;] direction LR digital1[&quot;Digital&quot;] analog1[&quot;Analog&quot;] antenna1[&quot;Antenna&quot;] digital1 --&amp;gt; analog1 --&amp;gt; antenna1 end channel[&quot;Channel&quot;] subgraph RX [&quot;Receiver&quot;] direction LR antenna2[&quot;Antenna&quot;] analog2[&quot;Analog&quot;] digital2[&quot;Digital&quot;] antenna2 --&amp;gt; analog2 --&amp;gt; digital2 end TX --&amp;gt; channel --&amp;gt; RXAs shown in the diagram above, the analog circuit elements in the transmitter and receiver, due to their inherent imperfections, are responsible for RF impairments. Examples include gain or phase imbalances in direct conversion modulators and demodulators and nonlinearity in power amplifiers.Before diving into details, let’s outline some common RF impairments: Thermal noise Amplifier distortion IQ imbalance DC offset Phase noise Carrier frequency offset (CFO)Thermal Noise, Noise Figure, and SensitivityWe begin with the simplest RF impairment: thermal noise. Despite its simplicity, it is easy to overlook during technical discussions or interviews. Thermal noise arises from the thermal energy of the environment around the transceiver. Its power density is given by the equation:\\[N_0 = kT\\]where $k$ is the Boltzmann constant and $T$ is the temperature in Kelvin. At room temperature, the thermal noise power density is approximately -174 dBm/Hz.Noise Figure (NF)When an analog signal passes through an RF device, noise is invariably added to the output. The noise figure quantifies the amount of noise a system introduces, representing the overall noise characteristics of a device. It is measured in dB (if written as F, it uses a linear scale). The relationship between input and output signal-to-noise ratio (SNR) is expressed as:\\[\\text{SNR}_\\text{out} = \\text{SNR}_\\text{in} - \\text{NF}\\]The lower the noise figure, the better the device performance. Typically, noise figures are less than 10 dB, and in low-noise devices, such as low-noise amplifiers (LNA), it can be below 1 dB.Friis’s FormulaThe Friis formula calculates the total noise factor of a cascade of stages, each with its own noise factor and power gain:\\[F_{\\text{total}} = F_1 + \\frac{F_2 - 1}{G_1} + \\frac{F_3 - 1}{G_1 G_2} + \\dots + \\frac{F_n - 1}{G_1 G_2 \\dots G_{n-1}}\\]A key insight is that the overall noise figure of a radio receiver is primarily determined by the noise figure of its first amplifying stage.To measure a device’s noise figure, one can use a noise figure meter, though it is often expensive and has limitations. Alternatively, the gain method using a spectrum analyzer and calculations can be employed.SensitivitySensitivity defines the minimum signal power required to achieve a specified bit error rate (BER). It can be calculated using the equation:\\[S_{\\text{min}} = -174 + 10\\log(\\text{BW}) + \\text{NF}_{\\text{rx}} + \\text{CNR}_{\\text{min}}\\]Here: -174 dBm/Hz is the thermal noise power density. $\\text{BW}$ is the signal bandwidth. $\\text{NF}_{\\text{rx}}$ is the receiver’s noise figure. $\\text{CNR}_{\\text{min}}$ is the minimum required carrier-to-noise ratio (different from SNR).From this equation, the most effective way to improve sensitivity is to reduce the receiver’s noise figure." }, { "title": "漏屋偏逢连夜雨", "url": "/posts/2nd-chance/", "categories": "logs", "tags": "", "date": "2024-12-14 01:05:00 -0800", "snippet": "最近我面试了一个一线大厂的 Wireless System Integration Engineer 的职位. 其实这是第二次面试这个职位了, 一年前我没有通过 full panel interview, 实在是很多基础知识不过关.因为 HM 人非常 nice, 对我也非常信任, 所以这回给了我第二次面试机会. 在这段困难的时间里, 有一次大厂的面试对我实在是太重要了, 可以说可能是一个 life changing 的机会. 所以在跟 HM 聊完后, 我认真准备了许久, 查缺补漏. 经历了 HR, HM 以及一整天的 full panel interview, 过了一周, HR 通知我通过了技术面试, 只需要等 leadership 的审批就好了.由于某些神秘的因素, 最终决定迟迟没有给出, 一直到这周一, HR 给我电话说没我有通过 leadership 的批准.这意味着我永远没有机会能够加入这家梦想中的公司了.这真是晴天霹雳, 我一度感觉呼吸都非常艰难, 晚上无法入睡. 旧伤未愈, 又添新创.接下来就是标准的悲伤五阶段: 否认, 愤怒, 讨价还价, 沮丧和接受. 不可能吧, 我的技术面试明明没有问题. 我都已经开始想象 2025 开年就去可以离开阴雨的温哥华去晒太阳了. 有什么可能改变这个决定? (不, 这是最终决定.) 完了, 所有努力都付之东流, 永远不会有更好的机会了. 那就这样吧, 不要耽误我继续投简历找工作.但是我觉得有必要把我面试还能记得住的问题在这里记录一下, 也许对读者或者未来的自己有帮助.Wireless communication system 是一个巨大的专业领域, 可以细分为多个小方向.我个人觉得很少有人能对每一个细分领域都有深入研究.比如有的职位要求熟练使用 C/C++ 或者 HDL 语言来开发通信算法, 亦或者精通阵列信号处理, 波束成形, 了解信号编码方案, 还懂调度算法. 以上都不是我很熟悉的领域.我更加熟悉的是无线电信号本身的物理层(PHY), 以及上下游的链路层(MAC)和 RF 收发机: transceivers.我的这次面试中, 除了我以前工作内容, 剩下的大部分题目都是围绕 RF transceiver 以及 RF 损伤 (RF impairment) 展开的. 接下来的几篇文章中, 我会尝试有条理地总结一下最核心的内容." }, { "title": "回归, 也是重启", "url": "/posts/return/", "categories": "logs", "tags": "", "date": "2024-12-11 12:14:00 -0800", "snippet": "最近一段时间, 一切都变得混乱不堪, 进入人生的至暗时刻. 直面坑脏与险恶带来的打击, 我可以被动接受, 也可以主动选择.我选择回归我的生活, 重启这个博客, 记录我的学习心得." }, { "title": "A Simple Parser in C Using Getopt", "url": "/posts/getopt/", "categories": "Programming, C", "tags": "c, parser, getopt", "date": "2022-06-18 04:20:00 -0700", "snippet": "In Python, there is an official module called argparse that provides a versatile command-line parser.Things are a little bit different in C, though.The GNU’s getopt() function is used to parse the command-line arguments with limited functionalities.In this post, I will show how to use getopt() to parse command-line arguments in C.Getopt in an ExampleThe basic usage of getopt() is as follows:#include &amp;lt;unistd.h&amp;gt;int getopt(int argc, char **argv, char *optstring);The argc and argv are passed from main() in C.The optstring is a string of characters that specifies the valid options.For example, a string &quot;abc:d:&quot; means that the valid options are -a, -b, -c, and -d.Characters followed by a colon to indicate an option argument is to follow.So in this example, they are -c argument and -d argument.The argument is saved in an external variable optarg as a string.The getopt() function incrementally parses a command-line argument list argv and returns the next known option character.If there are no more options, -1 is returned.In practice, the getopt() function is used in the following way:#include &amp;lt;stdio.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;unistd.h&amp;gt;int main(int argc, char *argv[]){ int c; while ((c = getopt(argc, argv, &quot;ab:c&quot;)) != -1) { switch (c) { case &#39;a&#39;: printf(&quot;option a\\n&quot;); break; case &#39;b&#39;: printf(&quot;option b with value &#39;%s&#39;\\n&quot;, optarg); break; case &#39;c&#39;: printf(&quot;option c\\n&quot;); break; case &#39;?&#39;: printf(&quot;unknown option\\n&quot;); break; default: abort(); } } return 0;}Limitations The getopt() function does not support long options, only single-character options are supported. There is no type casting or checking in the arguments, so extra care should be taken to make sure the arguments are correct. It cannot generate help messages. You will have to write your own help messages by adding a -h option.Further ReadingRead the getopt(3) manual page using man 3 getopt to learn more about what getopt can do for you.I also found another well-written blog on this topic you may be interested in.That is all for this post.Hasta Luego." }, { "title": "FFT-Based FIR Filtering Using Overlap-Add Method: a Matlab Implementation", "url": "/posts/fir-fft/", "categories": "DSP essentials", "tags": "dsp, fft, fir, overlap-add, matlab", "date": "2022-05-24 16:00:00 -0700", "snippet": "You have a very long signal, and you want to filter it with an FIR filter.The signal can be a stream of radio or audio, and you are going to implement it on a resource-constrained device, an FPGA or an MCU.This looks like a simple task for newbies, what could be wrong?The Memory is LimitedA common mistake beginners make is loading the entire signal to the memory and then filtering it.This could work in Matlab, but there are many issues when implementing it on real hardware.First, the signal can be very long, and the memory (or registers in an FPGA) is limited.The memory is precious, and you don’t want to eat it all up and crash your device.Second, it is a waste of time if you start the filtering until the end of the signal stream.The normal way to do it is once a block of the signal is ready, you filter it, and then you wait for the next block.It can be considered a producer-consumer problem, and there are standard implementations in each language.Overlap-Add MethodWe know that the DFT provides an efficient way to compute the convolution (or linear filtering) of two signals in the frequency domain (go back to any DSP textbook if you don’t know about it).To filter a very long sequence, two DFT-based approaches are the overlap-add method and the overlap-save method.Both of them break the signal into blocks and then compute the convolution of each block independently, and then combine the results in a certain way.We will only discuss the overlap-add method here and focus on the implementation in Matlab.The theory and how it accelerates the filtering can be found in this blog post.The general steps are find out the optimal NFFT and signal block size based on the FIR filter length. convert the FIR filter to the frequency domain. and initialize the output signal. loop each block of the signal, convert it to the frequency domain, and compute the dot product of the frequency domain of the FIR filter and the frequency domain of the signal block. convert back the result to the time domain, and add it to the output signal with an overlap.The Matlab ImplementationNote that this code is modified from the Matlab function fftfilt in the Matlab Signal Processing Toolbox.I made it more readable and easy to understand, and I also added some comments to explain the code.function y = fft_filter(b,x) % Overlap-add method for FIR filtering using FFT. % y = fft_filter(b,x) filters x, with the FIR filter specified by the % coefficients b, using the overlap/add method, and internal % parameters (FFT size and block length) that guarantee efficient % execution. % Check validity of input % I found it extremely useful to check the validity of the input % and to make the code more readable. no need to write a group of % if-else statements anymore. % here I require the input to be a column vector. validateattributes(b,{&#39;double&#39;},{&#39;column&#39;},&#39;fft_filter&#39;,&#39;B&#39;,1); validateattributes(x,{&#39;double&#39;},{&#39;column&#39;},&#39;fft_filter&#39;,&#39;X&#39;,2); % count the number of element for x and b nx = size(x,1); nb = size(b,1); % determine the most efficient NFFT if nb &amp;gt;= nx || nb &amp;gt; 2^20 % take a single FFT in this case nfft = 2^nextpow2(nb + nx -1); % 2^ceil(log2(nb + nx -1)) blockLen = nx; else % this is the computation cost of the FFT for each NFFT fftflops = [ 18 59 138 303 660 1441 3150 6875 14952 32373 69762 ... 149647 319644 680105 1441974 3047619 6422736 13500637 28311786 ... 59244791 59244791*2.09]; nfftList = 2.^(1:21); nfftValid = nfftList(nfftList &amp;gt; nb-1); fftflopsValid = fftflops(nfftList &amp;gt; nb-1); % NFFT = blockLen + nb - 1, to avoid circular convolution blockLenList = nfftValid - (nb - 1); % minimize (number of blocks) * (number of flops per fft) [~,ind] = min(ceil(nx./blockLenList).*fftflopsValid); nfft = nfftValid(ind); % must have nfft &amp;gt; (nb-1) blockLen = blockLenList(ind); end B = fft(b,nfft,1); % init output y y = zeros(size(x),&#39;like&#39;,1+1i); istart = 1; % main loop for the overlap-add method % this is a good example how to take care of the edge case while istart &amp;lt;= nx iend = min(istart+blockLen-1,nx); X = fft(x(istart:iend,:),nfft,1); yblock = ifft(X.*B,[],1); yend = min(nx,istart+nfft-1); y(istart:yend,:) = y(istart:yend,:) + yblock(1:(yend-istart+1),:); istart = istart + blockLen; end % let the output be real if the input is real if isreal(b) &amp;amp;&amp;amp; isreal(x) y = real(y); endendIn this post, we not only reviewed a divide-and-conquer way to deal with long signals but also implemented the overlap-add method in Matlab.I hope you can learn one or two coding tricks from this post too." }, { "title": "Matlab Development in Visual Studio Code", "url": "/posts/matlab-vscode/", "categories": "Development Tools", "tags": "matlab, vscode", "date": "2022-05-15 13:00:00 -0700", "snippet": "I almost use Matlab daily, and I see it is evolving in every release.However, I always have some complaints about its outdated GUI:The heavy toolbar reminds me of the MS office 2007.I know it can be hidden, but these useful buttons will be hidden too.In addition, there is no dark theme, making it difficult to work at night.In this post, I will show you some alternative ways to use Matlab.Matlab IDEThe Matlab we are talking about has multiple meanings: the programming language with an interpreter, and the Matlab desktop with a GUI.If you are familiar with other programming languages, you will know that such an integrated development environment (IDE) is not always necessary, and there may be many IDEs available.To start Matlab without the desktop (Linux and macOS), you can use the command line:matlab -nodesktopThen you will enter the Matlab interactive terminal.For more startup options, for example -nojvm, see the Matlab documentation.My point is that the Matlab desktop is not necessary to run Matlab scripts, and we can use a third-party IDE to run Matlab scripts.As for 2022, the VSCode is de facto the go-to IDE for coding in multiple languages.VSCode extensions for MatlabTo make Matlab work in VSCode, you need to install some extensions.There is a one-click solution called Matlab Extension Pack.It includes 6 extensions, some of the important ones are: MATLAB for Visual Studio Code: basic language support for MATLAB to VSCode. You will need to set up the linter (mlint) to make the most of it. Matlab Code Run: run Matlab scripts in VSCode. Open the command palette (under “View” or with shortcut ctr+shift+p) and find the “Run Matlab File” command. Matlab Interactive Terminal for VSCode. This extension allows you to start an interactive Matlab session in VSCode like other terminals. MATLAB Engine API for Python, installations instruction is available here. I had some struggles with this extension installation on macOS, hope you can pull it out.These are unofficial extensions and many critical functions are missing.There is no debug support, and no variable window (workspace), so it is not meant for serious work.I heard rumors that Matlab is going to remake its GUI in a future release, and the Matlab online has already shipped with a dark theme (but still the old GUI layout).I hope they can have a VSCode-like GUI layout, and get rid of the JVM if possible.All right, that is all for this post. Thank you for reading." }, { "title": "Resampling: the Fourier Method", "url": "/posts/resample-fourier/", "categories": "DSP essentials", "tags": "dsp, fourier, sampling, matlab", "date": "2022-05-07 15:00:00 -0700", "snippet": "In the last post, we saw how to downsample a signal using the polyphase FIR filter.In fact, the polyphase FIR filter can be used for upsampling as well, or generally speaking, for resampling.In Scipy, there are two resampling functions: resample and resample_poly.The default scipy.signal.resample function is used to resample a signal using the Fourier method.And the scipy.signal.resample_poly function is used to resample a signal using the polyphase FIR filter.In this post, we will see how the Fourier method works.Performance and BenefitsBefore going into detail, let’s see how the performance of the Fourier method compares to the polyphase FIR filter.According to this document: This polyphase method will likely be faster than the Fourier method in scipy.signal.resample when the number of samples is large and prime, or when the number of samples is large and up and down share a large greatest common denominator.However, the Fourier method is more flexible and can be used for other purposes.The benefits of the Fourier method are: The resulting frequency can be controlled with a much smaller granularity. the downsampled signal can be chosen from any band of the original signal, not just the low-frequency band. Similarly, the upsampled signal can have the original signal set to an arbitrary frequency, not just the DC.MethodAs the name suggested, the Fourier method resamples a signal in the frequency domain.The components in the low-frequency band are the same in the frequency domain no matter whether it is downsampling or upsampling.The resampling is done by removing or adding the components in the high-frequency band.Therefore, the Fourier method resampling has three general steps: Transform the signal to the frequency domain using the fast Fourier transform (FFT). Remove the desired amount of high-frequency components for downsampling, or add the desired amount of zeros to the high-frequency band for upsampling; Transform the signal back to the time domain using the inverse fast Fourier transform (IFFT) and compensate for the power difference.During the FFT and IFFT, the number of points equals the number of signal samples.The number of frequency samples to remove or add can be found by the difference between the length of the original signal n_original and the resampled signal n_resampled.If the sampling rate of the original signal and the resampled signal are fs_original and fs_resampled, respectively, then the length of the resampled signal is n_resampled = (fs_resampled / fs_original) * n_original` and round to the nearest integer.If the band of interest is not the low-frequency band, or around DC, a frequency shift can be introduced in the time domain.For the downsampling case, the wideband signal is multiplied by a carrier such that the band of interest is shifted to the low-frequency band (around DC), and then the signal is transformed to the frequency domain for resampling.For upsampling case, the resulting wideband signal is multiplied by a carrier such that the band of interest is shifted to the desired frequency.Demo CodeHere I will show you how to use the Fourier method to downsample a complex signal using Matlab.The upsampling case is similar.n_original = length(original_signal);% frequency shifted by fc Hzt = (0:n_original - 1) / fs_original;original_signal = original_signal .* exp(-1j * 2 * pi * fc * t&#39;);% FFTft_original = fft(original_signal);n_resampled = round((fs_resampled / fs_original) * n_original);% initialize the resampled signalft_resampled = zeros(n_resampled, 1);% downsampling and keep the low-frequency bandft_resampled(1:floor(n_resampled/2)) = ft_original(1:floor(n_resampled/2));ft_resampled(ceil(n_resampled/2):end) = ft_original(n_original - ceil(n_resampled/2) + 1:n_original);% IFFT and compensate for the power differenceresampled_signal = ifft(ft_resampled) * (length(ft_resampled) / length(original_signal));All right, that is all for this post. Thank you for reading." }, { "title": "Polyphase FIR Filter Downsampling", "url": "/posts/polyphase-decimator/", "categories": "DSP essentials", "tags": "dsp, polyphase, sampling, matlab", "date": "2022-04-23 02:00:00 -0700", "snippet": "This is a long-delayed post.As a father of two, who is living in one of the most expensive cities in the world, life is full of challenges.In most cases, after decomposition, they always go down to two reasons: the lack of money and/or time.It’s a simple truth, but I took years to realize it.Many years ago when I started writing DSP code, all I cared about was the correctness.My code used to have no readability, no structure, and no efficiency.Especially, when using Matlab, I used to pay no attention to the memory or CPU resource allocation, unless it is a heavy task or is going to be implemented on the hardware.Therefore, I want to write a series of posts on how to efficiently implement some DSP algorithms.I am going to start with the polyphase FIR filter downsampling.Conventional downsamplingDownsampling normally means reducing the sampling rate of a given digital signal by an integer factor $M$.According to the sampling theorem, we can not downsample a signal simply by keeping every Mth sample.Otherwise, there will be aliasing, or in other words, high-frequency components will be mixed into the downsampling output.Therefore, before decimation, a low pass filter (anti-aliasing filter) is required to remove the high-frequency components.The anti-aliasing filter is normally an FIR filter.If the length of the filter is fir_len, to output one sample, we will need fir_len multiplications.The multiplication cannot be shared between samples, so if the length of the signal is sig_len, it requires fir_len * sig_len multiplications.However, after decimation, only sig_len / M samples are left, which means, the effective number of multiplications is fir_len * sig_len / M, and other multiplications are wasted.Polyphase FIR filter downsamplingThe most interesting part of polyphase FIR filter downsampling is that it downsamples the signal first and then does the filtering, such that the multiplications are applied only to the leftover samples.As always, Matlab has a document to explain this algorithm.This reversed order of downsampling (or upsampling) and filtering is called multirate noble identity.I am not going to past all the equations and plots here, but to explain the idea.The polyphase FIR filter downsampling is a new structure.It is a decimator that is implemented using a polyphase filter.The first step of downsampling is to split the signal into $M$ sub-signals, and each sub-signal is a downsampled version of the original signal, so there is no sample discarded as the conventional downsampling.The second step is to filter each sub-signal with a sub-filter.Just like the sub-signals, the sub-filters are downsampled versions of the original low-pass FIR filter.The initial sample (or phase) when downsampling the low-pass filter is different for each sub-filter.That is why the sub-filters are called polyphase filters.Illustration and demo codeThere is an example of a polyphase FIR filter downsampling in the following figure, where the signal is downsampled by a factor of $M = 3$.The impulse response of the low-pass FIR filter is $h$, and for demonstration purposes, its length fir_len is set to 6.The input signal $x$ is split by a commutator switch as shown below.The demo code is as follows.The input signal $x$ and the impulse response $h$ are defined for demonstration purposes.dsp.FIRDecimator is a Matlab built-in object that implements the polyphase FIR filter downsampling.We can see that our output y_polyphase is the same as the reference output y_ref.x = (0:11)&#39;;M = 3;h = (0:5)&#39;;% use Matlab built-in functionfirdecim = dsp.FIRDecimator(M,h);y_ref = firdecim(x);fir_len = length(h);% if the fir_len is not intger multiple of fir_len, padding zerosif (rem(fir_len, M) ~= 0) nzeros = M - rem(fir_len, M); h = [h; zeros(nzeros,1)]; endlen = length(h);ncolm = len / M;polyphase_filt = flipud(reshape(h, M, ncolm));% init outputnx = length(x);y_polyphase = zeros(floor((nx-1)/M)+1,1);y_polyphase(1) = x(1) * polyphase_filt(end, 1);% init filter register to store xfilt_reg = zeros(size(polyphase_filt));filt_reg(end,2) = x(1);for idx = 2:length(y_polyphase) xst = (idx-2) * M + 2; filt_reg(:,1) = x(xst:xst+M-1); y_polyphase(idx) = sum(polyphase_filt .* filt_reg, &#39;all&#39;); filt_reg = circshift(filt_reg,1,2);endThat is all for this post. Hope you enjoy it." }, { "title": "Helium: IoT on the Blockchain", "url": "/posts/helium/", "categories": "Wireless Communication, Application", "tags": "lora, blockchain, cryptocurrency", "date": "2022-03-26 04:00:00 -0700", "snippet": "A few weeks ago, I was asked for opinions on Helium, so I did some research on their website and tried to figure out what they are doing and how it works.In this post, I would like to share my personal views on this “decentralized wireless infrastructure”.Disclaimer: I am NOT providing any financial or investment advice.What is Helium?In my opinion, it includes three layers: a globally distributed, LoRaWAN-enabled IoT network a blockchain that produces cryptocurrency called HNT a possible distributed 5G networkDistributed IoT networkOn the first layer, a LoRa IoT network is nothing new, and it is a mature technique long age.However, a globally distributed wireless network is never seen before.Normally, an IoT network is owned by one company and the coverage is limited to a certain area, a house or a factory for example, where the hotspots are installed and maintained.If the IoT devices need to be deployed in a very large area, a city, or a country, for example, the to-go choice is using the existing cellular network, and the standards are LTE-M, NB-IoT, etc.All these existing techniques can be categorized as centralized solutions, whereas the Helium network is claimed to be a distributed or decentralized solution.The hotspots are not owned by a company, but by individuals, the contributors.Anyone can buy a transceiver from Helium, plug it into their home network, and start hosting a hotspot.It is believed that as long as enough contributors host the hotspots around the world, the Helium network can have global coverage.According to their website, their devices transmit signals on the 915 MHz band (or 868 MHz in the EU).Although the hotspot is said to have long-range coverage with the sub-G Hz frequency, a global coverage still requires countless hotspots.CryptocurrencySo why the people would like to host and maintain the hotspots in the first place?The secret is the cryptocurrency: HNT.If you have ever heard of any kind of cryptocurrency, Bitcoin or Ethereum, the HNT is not much different.The HNT is rewarded to the hotspot hosts and can be converted to the data credit to access the Helium network.Most importantly, it is tradeable and cashable.The mining is not like other cryptocurrencies, you don’t need to run algorithms on expensive GPUs to prove your work, but to host hotspots and prove your coverage.The people who host the hotspots are compensated with the HNT which is equivalent to real money, so they have the motivation to host as many hotspots as possible.On the other hand, the users pay HNT to let their IoT devices access the Helium network, so they need to buy HNT on the market with real money.Sounds like a perfect closed loop.Distributed 5G networkThis blog gives some details regarding the future Helium 5G network.In summary, people buy 5G base stations (by FreedomFi) instead of IoT hotspots and the base stations will operate on the CBRS band.The CBRS stands for Citizens Broadband Radio Service and is a 150 MHz wide broadcast band of the 3.5 GHz band (3550 MHz to 3700 MHz) in the United States.Don’t forget, it is also compensated with the cryptocurrency, HNT.How I see the Helium networkWhen wireless meets blockchainI have to say, as a wireless expert, I am very excited to see this innovation:the mature wireless technique wrapped by the hottest concept, so the traditional industry can also enjoy the dividends of blockchain technology.I am not saying it is a scam or outdated, the technique is solid and the potential applications are real.At least it is a real-life project, not just burning GPUs.However, like all blockchain projects, speculation is inevitable.People flock in, and the only purpose is to mine the cryptocurrency as much as possible.It is helpful for the project to expand.The management team and the steak holders are happy to see this situation: the value of their cryptocurrency is soring, and they can cash out and achieve financial freedom.The coverage issueSo far so good, but remember, Helium is not only a blockchain but also an IoT network.It has a specific application in the physical world: connecting things to the Internet.If I were to connect my product to an IoT network, what will be my consideration?A stable connection that covers all the possible areas is the priority, and the power consumption and the cost may come second.The coverage map shows a lot of green dots in North America and Europe.This is “proof” of global coverage of the Helium network.But an illustration on this scale can be misleading.Are they represent the hotspots or coverage?Are these hotspots still active?Because if the HNT value goes down, just like other cryptocurrencies, the hotspot owners are not willing to turn on the hotspot all the time.In addition, to earn more HNT, it is best to deploy the hotspot close to other hotspots, so you will get more proof of coverage.So to deploy a hotspot to a rural area is not profitable, which may limit the expansion of its coverage.Decentralization is both an advantage and a fatal disadvantage in terms of network coverage.A centralized telecom company provides a stable network and will not turn off a station due to a currency’s value.It will also build stations to expand its network coverage as reasonably much as possible.Will decentralization prevail in the end? I don’t know, but I seriously doubt this decentralized IoT network.The problem with 5GLet’s talk about the Helium 5G network.I think this is more like a future vision to boost the HNT’s market value than a real application.We know the deployment of a 5G network is extremely expensive and requires domain expertise.Only China is capable to build the world’s largest 4G/5G network as well as other engineering wonders.The personal host 5G station costs a few thousand dollars, not as expensive as a real 5G station, but still 10 times more than a LoRa hotspot (which I believe is also too expensive).The coverage area is much smaller than the LoRa hotspot due to the higher signal frequency.Not to mention that the CBRS band could be very noisy like the 2.4G ISM band.Do you really want your 5G phone works on an unstable, no coverage guaranteed network?Most importantly, it is not secure.The base stations are hosted by individuals, and this sounds like an IMSI-catcher to me.If the station is hacked or the code is modified, all the traffic through your phone and your identity will be vulnerable to the third party.Closing statmentSo is it a scam? Maybe not.With these many flaws, HNT can still be valuable.There are so many kinds of cryptocurrencies that have no physical applications but are still popular.A cryptocurrency or any currency can be valuable as long as there is a backing story that many people believe.But as an IoT network, I am not going to choose the decentralized Helium network to deploy my application, unless the coverage is assured in the area of interest.Do you know there is another existing global “crowdsourcing” IoT network, that has billions of hotspots owned by the people, centralized management, and no cryptocurrency involved?That is Apple’s Find My network!" }, { "title": "Setup USRP on an M1 Macbook Air", "url": "/posts/usrp-macos/", "categories": "Wireless Communication, SDR", "tags": "usrp, macos", "date": "2022-03-19 11:00:00 -0700", "snippet": "I am a big fan of Apple products, but when working with a USRP, a Linux PC is always my first choice.Recently, my wife won an M1 Macbook Air in her company’s lottery (how lucky she is!), so I decided to test its compatibility with my USRP B200mini.In this blog, I going to share the process of installing the driver and benchmark it.Binary installationI am not a hard-core developer, so I never build source code myself if the binary file is available.From the USRP manual page, it is recommended to use MacPorts for the installation, but I prefer Homebrew.So the first step is to install Homebrew if you don’t have it. The Homebrew and MacPorts are packages managers just like the apt tool in Debian/Ubuntu.The second step is to isntall the UHD (the driver and tools for USRP):brew install uhdAlternatively, the installation of GNURadio will have the UHD installed too.Since I will need the GNURadio anyway, it is best to only install the GNURadio, otherwise, I will have two copies of UHD installed.PrefixThe concept of prefix confused me for a while when I first met it.From my understanding, it is the location where the packages (and the Homebrew itself) will be installed, and in our case, they are GNURadio and UHD.The prefix is /usr/local for macOS Intel, and /opt/homebrew for Apple Silicon (and my M1 Macbook Air).Normally, the executable files are installed in places like /usr/bin, /bin, /usr/sbin, where you need sudo privilege to add or remove stuff.It is dangerous and you are likely to break your system.However, with the prefix, you will have peace in mind: you don’t need sudo when you brew install, and it won’t crash your system when you accidentally delete a file.It is something like the virtual environment in Python. I can still remember the day I deleted my Ubuntu desktop when I was trying to upgrade the Python.Anyway, all you need is:brew install gnuradioAnd the GNURadio will be installed in the prefix folder.Download UHD imagesBefore using the USRP in each power cycle, a UHD image is automatically copied into the USRP to initialize the internal FPGA.You will have to manually download them after the installation of UHD.There is a Python script for it:/opt/homebrew/Cellar/uhd/4.1.0.5_1/lib/uhd/utils/uhd_images_downloader.py Note that this is the location for Mac with Apple silicon, and you may have a different UHD version.You can run it directly, but if Python complains, you may try another Python interpreter (from Conda for example) to run it.After a while, all images are saved in the folder /opt/homebrew/Cellar/uhd/4.1.0.5_1/share/uhd/images/.Next, connect the USRP to the Macbook. Because there is no USB Type-A port on the Macbook Air, I used a Type-A to Type-C adaptor to connect the USRP.To test the connectivity, run uhd_usrp_probe command. I have the printout like this:If you receive a warning message below, this is either you didn’t download the images properly, or the system environment variable ‘UHD_IMAGES_DIR’ is not set correctly.[WARNING] [B200] EnvironmentError: IOError: Could not find path for image: usrp_b200_fw.hexUsing images directory: &amp;lt;no images directory located&amp;gt;Set the environment variable &#39;UHD_IMAGES_DIR&#39; appropriately or follow the below instructions to download the images package.Please run:/opt/homebrew/Cellar/uhd/4.1.0.5_1/lib/uhd/utils/uhd_images_downloader.pyI got this warning when starting GQRX.This is because the software needs the environment variable ‘UHD_IMAGES_DIR’ to locate the UHD images and send them to USRP.The solution is to use the export command to set the environment variable or add the variable to your ~/.zshrc (new macOS comes with zsh instead of bash) file.export UHD_IMAGES_DIR=&quot;/opt/homebrew/Cellar/uhd/4.1.0.5_1/share/uhd/images/&quot;BenchmarkingFinally, I can test the performance of the USRP on the Macbook:/opt/homebrew/Cellar/uhd/4.1.0.5_1/lib/uhd/examples/benchmark_rate --rx_rate 56e6 --tx_rate 56e6But the results are very disappointing with a significant amount of dropped and overflowed samples.Benchmark rate summary: Num received samples: 538358291 Num dropped samples: 37804075 Num overruns detected: 330 Num transmitted samples: 443971320 Num sequence errors (Tx): 0 Num sequence errors (Rx): 0 Num underruns detected: 95882 Num late commands: 0 Num timeouts (Tx): 0 Num timeouts (Rx): 0For receiving only mode, it can only run at 40 MHz without dropping samples.These are the results of a late 2020 Macbook, so the hardware has more than enough power to keep up with the USB 3 speed.In addition, the test result from a 2013 late Retina Macbook Pro is even worse: it can only run at 22 MHz without dropping samples, like the USB 2 speed.I had the same dropping/overflow issue when trying on a Windows PC, but no issue if switched to the Linux system.I suspect that there is an issue with the USB driver for macOS and Windows, but I have no evidence.That is why I always use Linux for USRP related development.That is all for today.Thanks for reading." }, { "title": "Why do I receive a Wi-Fi signal at 810 MHz?", "url": "/posts/wifi800/", "categories": "Wireless Communication, SDR", "tags": "usrp, wi-fi, fourier analysis", "date": "2022-02-20 09:00:00 -0800", "snippet": "A few months ago, when I was playing around with a USRP B200mini and GQRX (for spectrum visualization), I found a mysterious signal at around 810 MHz.It has 20 MHz bandwidth with a null DC.Pretty sure it is a Wi-Fi signal judging from the spectrogram, except that the center frequency is significantly off.So what exactly is it?I couldn’t find the answer on the Internet, and it took me a long time to figure it out by myself.So I going to do a retrospective analysis in this post.TroubleshootingBelow is the list of possible reasons: The signal exists at this frequency. Hardware issue with the USRP. Software issue with the GQRX.First, I used an HackRF One to check the signals at the same band, but nothing is there.This indicates that there is no Wi-Fi signal at 810 MHz, and it mack sense.Also, it is not the GQRX’s issue.So there must be something not right with the USRP.Before going further, let’s take a look at the frontend of Hackrf One.In the lower-left, there are 3 filters, and the first lowpass filter can block the interference above 2.3 GHz when looking at signals at 810 MHz.There is no such filter in the frontend of my USRP.This may explain the observation, but why the Wi-Fi signal is mixed into 810 MHz in the first place?Direct-conversion receiverIn fact, without the lowpass filter in the frontend, the HackRF One will receive interference too.To understand this, we must go back to the principle of the Direct-conversion or zero IF architecture, which is the most commonly used RF transceiver architecture.Analog Device has a nice technical article talking about the RF receiver architecture.As shown in the figure, the LO (Local Oscillator) frequency is set equal to the frequency of interest, so the received signal is directly converted to the baseband I (inphase) and Q (quadrature) signals.In other words, the RF signal is multiplied by the LO, so that the signal at the frequency of interest is shifted to zero frequency.HarmonicsBut the reference signal generated by the LO is not a pure sine wave, but more like a square wave.When there is a square wave, there are harmonics.That means except for the 810 MHz fundamental frequency, there should be 1620 MHz, 2430 MHz, 3240 MHz … components generated by the LO.So it is the third-order harmonic of the LO that brings the 2.4 GHz Wi-Fi signal down to the signal at 810 MH.If so, I should get the Wi-Fi signal at 1220 MHz too, right? No.According to the Fourier analysis, if an infinite square wave has a duty cycle of 50%, there are odd-order harmonics only.And yes, I did see the Wi-Fi signal again at 490 MHz, which corresponds to the fifth-harmonic of LO.That is all for today.Thanks for reading." }, { "title": "Power Spectrum: something I wish I could understand early (3)", "url": "/posts/spectrum3/", "categories": "DSP essentials", "tags": "dsp, power spectrum, python, matlab", "date": "2022-02-19 08:00:00 -0800", "snippet": "In this post, I am going to share a set of Python functions that can calculate the power spectral density, spectrogram, and persistence spectrum of a given (real or complex) one-dimensional signal.The functions are largely based on the Python library: Matplotlib.For demonstration purposes, the original codes are simplified to make them reader-friendly.I want to point out that the implementation of the persistence spectrum is original, and I found this plot is useful and can replace the spectrum in many aspects.Stock functionsIn the beginning, I want to show how to use stock matplotlib functions: specgram and psd.For comparison, I will recreate the test signal according to a Matlab document, where a narrowband signal is embedded within a broadband chirp signal.Keep an eye on the persistence spectrum in the example, and I will talk about it later.import numpy as npfrom scipy.signal import windows, chirpimport matplotlib.pyplot as plt# generate the signal under testfs = 1000t = np.arange(0, 500, 1/fs)x = chirp(t, 180, t[-1], 220) + 0.15 * np.random.randn(len(t))idx = int(np.floor(len(x)/6))x[:idx] = x[:idx] + 0.05*np.cos(2*np.pi*t[:idx]*210)Then let’s plot the spectrogram and PSD.Under the hood, both of them are generated from the Short-Time Fourier Transform (STFT) of the signal.The process is very similar to the periodogram generation we talked before:in short, the signal is divided into small segments and the FFT is applied to each segment.# generate the power spectral densityfig, ax = plt.subplots()ax.psd(x, Fs=fs)ax.set_xlim([100, 290])ax.set_ylim([-45, -15])ax.set_yticks(np.arange(-45, -10, 5))plt.show()Here I will keep all arguments as default.We can only see the PSD of the wideband chirp signal, and the weak single tone is disappeared.# generate the spctrogramfigure, axes = plt.subplots()[spectrum, freqs, t, _] = axes.specgram(x, NFFT=512, Fs=fs, noverlap=256, cmap=&quot;jet&quot;, vmin=-50, vmax=0)axes.set_ylim([100, 290])axes.set_xlabel(&#39;Time (minutes)&#39;)axes.set_ylabel(&#39;Frequency (Hz)&#39;)plt.show()Now we can see both signals in the spectrogram.The overlap argument indicates the number of overlapped samples of two nearby segments, which can reduce the noise interference, at the cost of reduced frequency resolution and more computation.This is a major improvement of Welch’s Method from the original periodogram.I choose “jet” for the color map argument cmap, because it is the closest to the default Matlab color map.Spectrogram and PSDTo plot our own PSD and spectrogram, we first need two helper functions.def _stride_windows(x, n, noverlap=0): &quot;&quot;&quot; a simplified version of matplotlib function with the same name https://github.com/matplotlib/matplotlib/blob/710fce3df95e22701bd68bf6af2c8adbc9d67a79/lib/matplotlib/mlab.py#L218 more about as_strided function https://zhuanlan.zhihu.com/p/64933417 &quot;&quot;&quot; noverlap = int(noverlap) n = int(n) step = n - noverlap shape = (n, (x.shape[-1]-noverlap)//step) strides = (x.strides[0], step*x.strides[0]) return np.lib.stride_tricks.as_strided(x, shape=shape, strides=strides)This helper is used to generate signal segments with overlaps.We can also directly reshape the input signal into a two-dimensional matrix if no overlap is required.def _spectral_helper(x, Fs=1, NFFT=1024, noverlap=0): &quot;&quot;&quot; spectrual help for spectrum, spectrogram, and persistence spectrum NFFT is assumed to be the power of 2, at least is an even number &quot;&quot;&quot; # segmentation and windowing # window = np.hanning(NFFT) # Kaiser window is used in Matlab window = np.kaiser(NFFT, 20) result = _stride_windows(x, NFFT, noverlap) result = result * window.reshape((-1, 1)) # fft to each frame result = np.fft.fft(result, n=NFFT, axis=0) # convert to power result = np.real(np.conj(result) * result) freqs = np.fft.fftfreq(NFFT, 1/Fs) if np.iscomplex(x[0]): # twosided # center the frequency range at zero (fftshift) freqs = np.fft.fftshift(freqs, axes=0) result = np.fft.fftshift(result, axes=0) else: # onesided result = result[:NFFT//2 + 1, :] # scale for onesided spectrum, skip the DC result[1:, :] *= 2 freqs = freqs[:NFFT//2 + 1] # get the last value correctly, it is negative otherwise freqs[-1] *= -1 # divides by the sampling frequency so that density function has # units of dB/Hz and can be integrated by the plotted frequency value result /= Fs # Scale the spectrum by the norm of the window to compensate for # windowing loss; see Bendat &amp;amp; Piersol Sec 11.5.2. result /= (np.abs(window)**2).sum() t = np.arange(NFFT/2, len(x) - NFFT/2 + 1, NFFT - noverlap)/Fs return result, freqs, tThis is the core function of STFT computation. It processes the signal in the following steps: Each data segment is multiplied by the Kaiser window. Apply FFT to each segment and convert it to power. For complex signals, shift the result such that the DC is in the middle; for real signals, discard the negative frequency components and double the positive components. Normalize the results by the sampling frequency and the energy of the window.Make sure to follow all the steps to get the right power value.Fs = 1000NFFT = 1024noverlap = 782result, freqs, t = _spectral_helper(x, Fs, NFFT=NFFT, noverlap=noverlap)psd = 10 * np.log10(result.mean(axis=1))fig, ax = plt.subplots()ax.plot(freqs, psd)ax.set_xlabel(&#39;Frequency&#39;)ax.set_ylabel(&#39;Power Spectral Density (dB/Hz)&#39;)ax.grid(True)ax.set_xlim([100, 290])plt.show()So the PSD can be derived from the STFT result by averaging in time.Don’t forget to convert it to the dB scale.Next is the spectrogram.stft = 10 * np.log10(result + 1e-6)# find the extent in time and freqpad_xextent = (NFFT-noverlap) / Fs / 2xmin, xmax = np.min(t) - pad_xextent, np.max(t) + pad_xextentextent = xmin, xmax, freqs[0], freqs[-1]pwr_min, pwr_max = -50, 0fig, ax = plt.subplots()ax.imshow( stft, cmap=&quot;jet&quot;, extent=extent, vmin=pwr_min, vmax=pwr_max, origin=&#39;lower&#39;)ax.set_ylim([100, 290])ax.set_ylabel(&#39;Frequency&#39;)ax.set_xlabel(&#39;time&#39;)plt.show()It is basically to use imshow() to display the STFT results. However, there are some tricky points: The linear STFT value is converted to the dB scale. Note that you can only average the linear scaled STFT results, therefore, I can’t do it before the PSD plotting. The added small number, 1e-6 into linear scaled STFT is to avoid the potential log(0) that gives us negative infinity. Manually decide the “extent” and “vmin”, “vmax” to get the best imshow() display range. Don’t forget to set the “origin” argument to “lower”, otherwise, the default will make the frequency axis flip.The plots are alomst identical to the plots above, so I will not paste them twice.Persistence spectrumThe persistence spectrum is a beautiful way to display the time-variant signals.Someone call it intensity graded persistence display.I want to again quote this Matlab document to explain it: The persistence spectrum of a signal is a time-frequency view that shows the percentage of the time that a given frequency is present in a signal. The persistence spectrum is a histogram in power-frequency space. The longer a particular frequency persists in a signal as the signal evolves, the higher its time percentage and thus the brighter or “hotter” its color in the display. Use the persistence spectrum to identify signals hidden in other signals.So, it is a histogram of the STFT results, I am going to use np.histogram() function to plot it:nbins = 256pspectrum = np.zeros((nbins, len(freqs)))for idx_f in range(len(freqs)): pspectrum[:, idx_f], _ = np.histogram( stft[idx_f, :], bins=np.linspace(pwr_min, pwr_max, nbins+1), density=False )pspectrum = np.log(pspectrum + 0.5)fig, ax = plt.subplots()ax.imshow( pspectrum, aspect=&quot;auto&quot;, cmap=&quot;jet&quot;, extent=(freqs[0], freqs[-1], pwr_min, pwr_max), origin=&#39;lower&#39;, # vmin=-1, # vmax=3.)ax.set_xlim([100, 290])ax.set_xlabel(&#39;Frequency (Hz)&#39;)ax.set_ylabel(&#39;Power Spectrum (dB/Hz)&#39;)plt.show()For each frequency slot, I generate a histogram from the log STFT result.To enhance the low power signals, another log is applied to the histogram result.Finally, use the imshow() function to plot the persistence spectrum just like the spectrogram.Now, we can see both signals in the persistence spectrum.That is why I prefer it over the normal PSD plot.Noise floor issueBut if you take a look at the noise floor of my plot, it is about 6 dB lower than the plot from Matlab’s document.It confused me for quite a while.After a few unsuccessful communication with Mathworks after service, I finally found the reason.In my plot, the unit of the power is dB/Hz, in other words, the power is measured in a frequency bin of 1 Hz.And the plot from Matlab has a frequency resolution of about 4 Hz, so the power is measured in a frequency bin of 4 Hz.That is why the unit on the y-axis only says dB, not dB/Hz as it used to be.Therefore, the power measure in Matlab’s plot is 4 times higher (6 dB) higher than my plot.Mysteries solved!It’s all yoursyou can download and/or test my code here.I think this concludes today’s post.See you next time." }, { "title": "Power Spectrum: something I wish I could understand early (2)", "url": "/posts/spectrum2/", "categories": "DSP essentials", "tags": "dsp, power spectrum, matlab", "date": "2022-02-12 02:00:00 -0800", "snippet": "Real and complex signalsWhen doing the spectrum analysis, the signal is usually real-valued.However, when studying the baseband signal in wireless communications, the data is complex-valued.There is a significant difference in the processing of real and complex-valued signals for spectrum analysis.You may notice the periodogram function in Matlab has an argument ‘freqrange’ that can be ‘onesided’, ‘twosided’, or ‘centered’.Similarly in matplotlib, the function pyplot.specgram has an argument ‘sides’ can be ‘onesided’ or ‘twosided’.This is because, for real signals, the DFT results are mirrored (conjugated to be specific) at fs/2.In practice, only the spectrum from frequency 0 to fs/2 is shown.Note that, to make sure the energy of the displayed half spectrum is the same as the whole spectrum, the value of the half spectrum is doubled, except the DC.As for complex-valued signals, the DFT results are useful from 0 to fs.The only thing we need to be cautious of is the frequency that is conventionally displayed from -fs/2 to fs/2.So when using periodogram in Matlab, it is recommended to set ‘centered’ instead of leaving default or ‘twosided’(0 to fs).Whereas matplotlib can take care of it by default.For example, if an SDR has a sampling rate of 56 MHz, the effective signal bandwidth is 56 MHz, not 28 MHz.Isn’t it breaking the Nyquist sampling theorem?If you take a look at a diagram of an SDR, you can find the incoming signal is separated into two channels and they are multiplied by a pair of orthogonal carriers, then, sampled by two ADCs to generate the IQ signal.We can not strictly consider each signal from one channel contributes half of the spectrum, so it is not violating the sampling theorem.Parametric and nonparametric estimationYou may be told that the Periodogram or Welch methods for spectral estimation are nonparametric.In comparison, the Burg, Yule-Walker are parametric methods.What is the meaning of parametric anyway?This term is from statistics, and there is a course called statistical signal processing, which I don’t excel at.So I am going to copy some text from this Matlab documentation page. Parametric methods can yield higher resolutions than nonparametric methods in cases when the signal length is short. These methods use a different approach to spectral estimation; instead of trying to estimate the PSD directly from the data, they model the data as the output of a linear system driven by white noise and then attempt to estimate the parameters of that linear system.If you get confused, just remember, the parametric methods believe the signal is generated from a model or follows the distribution of a model, and the spectrum is a function of the model parameters.The spectral estimation is then becoming a model parameter estimation problem.For example, Burg and Yule-Walker methods assume an autoregressive (AR) model.The current date sample is a linear combination of a few previous samples and the noise.When it only depends on the last sample, it is equivalent to the Markov process.If the model is chosen correctly, the parametric methods have better performance.This is due to the prior knowledge carried by the model and the reduced uncertainties brought by the noise.Just like the Bayes’ theorem, with the help of prior probability, we can yield a better posterior probability.This is assuming we have the right prior knowledge, otherwise, the likelihoods (nonparametric methods) are all we can rely on.This reminds me of the concept of generative and discriminative models in machine learning.The generative classifiers try to find parameters for the prior distribution while the discriminative classifiers jump to the conditional probability directly.That is all for now.Next time, I will bring some real Python code to compute the spectrum, spectrogram, and persistence spectrum." }, { "title": "Power Spectrum: something I wish I could understand early (1)", "url": "/posts/spectrum1/", "categories": "DSP essentials", "tags": "dsp, power spectrum, python", "date": "2022-02-01 02:00:00 -0800", "snippet": "Other than the time plot, the power spectrum and the spectrogram (a plot that shows the signal in time and frequency domain) are probably the most important tools for digital signal analysis.Because of its importance, people invented so many algorithms to estimate and present it in various ways.In Matlab, you can use periodogram, pwelch, pspectrum, pburg, pmusic, and many more of them.It is so overwhelming for me at the beginning (and even now), but from time to time, I gradually get used to it and make sense of it.In this blog, I am going to talk about a few power spectrum-related short topics that confused me in the early days.Why power spectrumSo why bother power spectrum, why can’t we apply the Fourier Transform directly to the signal and get the frequency spectrum? This may be the first question many people will ask.If the signal is periodic or more specifically, deterministic, we can use the frequency spectrum to present the signal.However, most signals we are dealing with are stochastic (random, non-deterministic) signals, or with a stochastic component.In addition, these signals are usually infinite in length, and we can’t apply an infinite length of Fourier Transform.If we truncate the stochastic signal into segments and apply the Fourier Transform to each segment, we can find the frequency spectra are random in both magnitude and phase at a given frequency.The frequency spectrum analysis is only applicable to deterministic signals.As for stochastic signals, they can be analyzed statistically, or in our case, be averaged.Because of the random phase mentioned before, the mean of frequency spectra is probably zero.Although the frequency spectra are complex-valued, the power spectra are real-valued and can be averaged.The periodogram method is essentially the averaged power spectra alone multiply signal segments.What is the power spectral densityWhen we talk about the power spectrum, what we’re actually talking about is the power spectral density (PSD).Mathematically, we have to normalize the power in the frequency domain by the sampling rate.In another word, the value of PSD is the power per frequency unit.If we take a look at the plot from Matlab’s periodogram or the psd from Python’s matplotlib, the unit of the y-axis is dB/Hz when the sampling rate is given.But why do we want to normalize the power by the sampling rate?Let’s have a Python demo to find it out.We first generate two sine waves with Different frequencies (for visualization purposes). The sampling rates are 100 Hz and 200 Hz respectively. The same amplitude and same length in time. So they have the same energy, but the number of samples is different.import numpy as npimport matplotlib.pyplot as pltf_sig1 = 15fs1 = 100t1 = np.arange(0, 512/fs1, 1/fs1)sig1 = np.sin(2 * np.pi * f_sig1 * t1)f_sig2 = 25fs2 = 200t2 = np.arange(0, 1024/fs2, 1/fs2)sig2 = np.sin(2 * np.pi * f_sig2 * t2)If you are trying to calculate the energy of the two signals directly, you may find the energy of the second signal is twice the first one.That is because you forgot the time step during the integration.This will happen in the frequency domain too.Next, let’s find the power spectrum of the two sine waves.The numbers of samples for the two sine waves are deliberately set to 512 and 1024, so we can use the FFT size of 512 and 1024 directly.Note that, according to the Parseval’s theorem:\\[\\sum_{n=0}^{N-1} | x[n] |^2 = \\frac{1}{N} \\sum_{k=0}^{N-1} | X[k] |^2\\]To preserve the energy, the power in the frequency domain needs to be divided by N, and in our case, the FFT size.nfft1 = 512ft1 = np.fft.fft(sig1, nfft1)p1 = (ft1 * ft1.conj()).real/nfft1f1 = np.fft.fftfreq(nfft1, 1/fs1)nfft2 = 1024ft2 = np.fft.fft(sig2, nfft2)p2 = (ft2 * ft2.conj()).real /nfft2f2 = np.fft.fftfreq(nfft2, 1/fs2)plt.plot(f1, p1)plt.plot(f2, p2)plt.xlim((10,30))plt.xlabel(&#39;frequency (Hz)&#39;)plt.ylabel(&#39;power?&#39;)plt.show()We can find that the second sine wave shows twice the power of the first one, which is obviously wrong.To fix it, we can normalize the power in the frequency domain by the sampling rate, then the two power peaks (in the PSD plot) will have the same height.When preparing for this post, I found an interesting example inthis Matlab document.If you take a close look at the noise level of the same signal in the power spectrum and the persistence spectrum (we will talk about it in a later post), you can find the former is 6 dB lower than the latter.This is also because they are normalized differently.Can you figure out why the difference is 6 dB?Matlab didn’t tell you everythingto be continued" }, { "title": "RTL-SDR based ADS-B Receiver", "url": "/posts/rtlsdr/", "categories": "Wireless Communication, SDR", "tags": "rtl-sdr, ads-b", "date": "2022-01-23 14:57:00 -0800", "snippet": "In the last post, we talked a lot about the details of the ADS-B signal, but how can we receive the signal and use it to track aircraft in real-time? In this blog, I will show how to use RTL-SDR to build an aircraft tracker.RTL-SDRDVB-T dongles based on the Realtek RTL2832U can be used as a cheap SDR since the chip allows transferring the raw I/Q samples to the host.Almost all SDR enthusiasts start from RTL-SDR because of its affordable price. It costs $30 to $40 on Amazone.Although no other SDR can beat its price, you only get what you paid: the performance is very limited. You will find it in the specifications.RTL-SDRSpecifications center frequency: 500 kHz to 1.7 GHz. outputs 8-bit I/Q-samples. up to 3.2 MHz of instantaneous bandwidth (2.4 MHz stable). can only be used as a receiver, not a transmitter.It is not very powerful, so if you want to go professional, get a HackRF or USRP.Once you received the RTL-SDR connect the dongle to the PC and the antenna to the dongle. Place the antenna in an open place. Out door will give you the best performance, but indoor by the window will also do the work.You don’t have to expand the antenna, since you are receiving the GHz signal, which have very short wave length.Read this for more about the antenna.SoftwareI assume you have the RTL-SDR dongle and antenna ready. The next step is to install the supporting software.You can find help from the official QUICK START GUIDE.If you are using Linux (why not), Osmocom has a nicely written wiki page for RTL-SDR, and I highly recommend you to go through it for more details.rtl-sdrNow, you have Ubuntu installed on your PC or Raspberry Pi, you can use the apt package manager to install the binary files without compiling them.sudo apt install rtl-sdr librtlsdr-devWhere the rtl-sdr is a packet of primitive tools, and the librtlsdr-dev is the library for making dump1090 in the next step. rtl_sdr is used to record IQ samples to a file or to forward the data to a FIFO.Example: To tune to 392.0 MHz, and set the sample-rate to 1.8 MS/s, use:./rtl_sdr /tmp/capture.bin -s 1.8e6 -f 392e6 rtl_fm allows you to decode and listen to FM/AM/SSB radio. But you will need to install sox and use sox’s play command to play the audio.sudo apt-get install soxThen you can pipe the output from rtl_fm to play. Note that you can choose your own center frequency -f, and make sure the data rates -r are the same.rtl_fm -f 90.1e6 -M wbfm -s 200e3 -r 48e3 - | play -r 48e3 -t s16 -L -c 1 -A few more applications, such as police scanner, airband scanner, and pager decoder can be found here. rtl_adsb is a simple ADS-B decoder, maybe too simple. It can only demodulate the ADS-B message into HEX format. See the screen below. If you are satisfied with this result, you can stop here now, but if you like to have rich information and even a map with live aircraft locations, let’s continue.I will only list three tools, please refer to the Osmocom wiki page for more.There is also a Python library, pyrtlsdr for RTL-SDR development.dump1090Dump 1090 is a Mode S (ADS-B) decoder specifically designed for RTLSDR devices.To install it, you will need to compile it from the source code.I know that isn’t pleasant for many users, just get used to it.git clone https://github.com/antirez/dump1090.gitcd dump1090makeTo run the program in interactive mode, with networking support, and connect with your browser to http://localhost:8080 to see live traffic:./dump1090 --interactive --netYou can find a more readable table in the terminal.Also, there is a live air traffic map in your browser.Note that the screenshot below is from Kismet, but they are generally similar.Thanks for reading." }, { "title": "ADS-B Basics", "url": "/posts/ads-b/", "categories": "Wireless Communication", "tags": "ads-b", "date": "2022-01-19 10:00:00 -0800", "snippet": "IntroductionRecently, I was doing some research on the ADS-B signal, and I’d like to take this opportunity to organize and share my results. ADS-B stands for Automatic Dependent Surveillance - Broadcast, which is self-explanatory. The ADS-B is a type of broadcast signal from many civil aircraft that carries its location, altitude, speed, heading, identification, etc. The purpose is to prevent accidents by exchanging information with other aircraft and ground stations.The interesting part is that this signal is not encrypted, and can be easily received and demodulated. One can feel great achievement once decode it. As such, building an ASD-B receiver is like the second must-to-do project for software defined radio (SDR) enthusiasts. Of course, the first project is always an FM radio. As to the ADS-B receiver, I will talk about it in the next blog. Let’s first take a look at the signal itself from the wireless communication perspective.Parameters and the ModulationMatlab has a nice documentation on the ADS-B signals (Matlab has a lot of nicely written documentation!). So I will copy and paste some here.Mode-S (consider it as ADS-B) has the following properties: Transmit Frequency: 1090 MHz Modulation: Pulse Position Modulation Data Rate: 1 Mbit/s Short Squitter Length: 56 microseconds Extended Squitter Length: 112 microsecondsShort squitter messages contain the following information: Downlink Format (DF) Capability (CA) Aircraft ID (Unique 24-bit sequence) CRC ChecksumExtended squitter (ADS-B) messages contain all the information in a short squitter and one of these: Altitude Position Heading Horizontal and Vertical VelocityIn the physical layer, the ADS-B signal has a center frequency of 1090 MHz and occupies 1 MHz bandwidth. The Pulse Position Modulation (PPM) is not widely used, but it is very simple. As shown in the figure below, each symbol has two chips, where one has a high value and the other has a low value. If the first chip is high followed by low chip, this corresponds to the symbol being a 1. Alternatively, if the first chip is low followed by high chip, then the symbol is 0.Frame structureFrom the figure above, each ADS-B frame is 10 us long. The first 8 us is the preamble that can be used for synchronization. The following is the 122 us long data block which contains 122 bits data. I will briefly give the frame structure, and you can find more details here.BTW, this author also wrote a nice Python decoder for ADS-B signals. Import it, so you don’t need to build your own wheel to decode the ADS-B signals. Bit No. bits Abbreviation Information 1-5 5 DF Downlink Format 6-8 3 CA Transponder capability 9–32 24 ICAO ICAO aircraft address 33–88 56 ME Message, extended squitter (33–37) (56) (TC)) (Type code) 89–112 24 PI Parity/Interrogator ID To be continued in the next post." }, { "title": "This is the First Post", "url": "/posts/first-post/", "categories": "", "tags": "", "date": "2022-01-18 13:57:00 -0800", "snippet": "WelcomeThere is nothing here, yet.Will start posting soon.Hope you like the photoCentral Park After Snow" } ]
